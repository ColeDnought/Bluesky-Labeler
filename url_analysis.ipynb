{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918cf411",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from analysis_helpers import load_url_data, analyze_authors_comprehensive, add_domain_column\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "\n",
    "ALL_USERS = 'url_stream.csv'\n",
    "LABELED_USERS = 'train_data.csv'\n",
    "\n",
    "df = load_url_data(ALL_USERS)\n",
    "\n",
    "def to_did(url):\n",
    "    return url.split('/')[-1]\n",
    "\n",
    "labeled = pd.read_csv(LABELED_USERS)\n",
    "labeled['author'] = labeled['link'].apply(to_did)\n",
    "\n",
    "df = add_domain_column(df)\n",
    "\n",
    "author_stats = analyze_authors_comprehensive(df, labels_df=labeled)\n",
    "author_stats = author_stats[author_stats['label'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e724f5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis_helpers import populate_follower_count\n",
    "\n",
    "author_stats = populate_follower_count(author_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616f2753",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b170a70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'label'\n",
    "# feature_columns = ['unique_domains', 'unique_urls', 'avg_time_between_posts', 'followers_count', 'follows_count', 'follower_following_ratio']\n",
    "feature_columns = ['unique_domains', 'unique_urls', 'followers_count', 'follows_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19adb6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis_helpers import augment_data\n",
    "\n",
    "test_data = augment_data(author_stats, feature_columns, target_column, num_synthetic_rows=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7443d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Create a copy to preserve original data for the scaler\n",
    "test_data_original = test_data.copy()\n",
    "\n",
    "# Fit scaler on original data (BEFORE transforming)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(test_data_original[feature_columns])\n",
    "\n",
    "# Transform the data\n",
    "test_data[feature_columns] = scaler.transform(test_data[feature_columns])\n",
    "\n",
    "# Prepare features and target\n",
    "X = test_data[feature_columns]\n",
    "y = test_data[target_column]\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "classifier = DecisionTreeClassifier(\n",
    "    random_state=42,\n",
    "    max_depth=2,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=5,\n",
    "    max_features='sqrt',\n",
    "    class_weight='balanced'\n",
    ")\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_proba = classifier.predict_proba(X_test)\n",
    "\n",
    "def report_at_threshold(threshold: float = 0.5):\n",
    "    \"\"\"Higher threshold -> higher precision\"\"\"\n",
    "\n",
    "    # Get class labels\n",
    "    classes = classifier.classes_\n",
    "    spam_idx = list(classes).index('spam')\n",
    "\n",
    "    y_pred_high_precision = np.where(y_proba[:, spam_idx] >= threshold, 'spam', 'good')\n",
    "    \n",
    "    precision = precision_score(y_test, y_pred_high_precision, pos_label='spam', zero_division=1)\n",
    "    \n",
    "    recall = recall_score(y_test, y_pred_high_precision, pos_label='spam', zero_division=1)\n",
    "\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d510f626",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Get predictions at the chosen threshold\n",
    "THRESHOLD = 0.6\n",
    "spam_idx = list(classifier.classes_).index('spam')\n",
    "y_pred_threshold = np.where(y_proba[:, spam_idx] >= THRESHOLD, 'spam', 'good')\n",
    "\n",
    "print(f\"Classification Report (threshold = {THRESHOLD})\")\n",
    "print(\"=\" * 50)\n",
    "print(classification_report(y_test, y_pred_threshold, target_names=['good', 'spam']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313b1592",
   "metadata": {},
   "source": [
    "## Quick digression for logistic comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33d73a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Logistic Regression Model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_classifier = LogisticRegression(random_state=42, class_weight='balanced', max_iter=1000)\n",
    "lr_classifier.fit(X_train, y_train)\n",
    "y_pred_lr = lr_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77cee17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot decision boundaries for Logistic Regression\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from itertools import combinations\n",
    "\n",
    "# Encode labels to numeric values\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Get all pairwise combinations of features\n",
    "feature_pairs = list(combinations(range(len(feature_columns)), 2))\n",
    "\n",
    "n_plots = len(feature_pairs)\n",
    "n_cols = 3\n",
    "n_rows = (n_plots + n_cols - 1) // n_cols\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5 * n_rows))\n",
    "axes = axes.flatten() if n_plots > 1 else [axes]\n",
    "\n",
    "for idx, (i, j) in enumerate(feature_pairs):\n",
    "    X_pair = X.iloc[:, [i, j]].values\n",
    "    \n",
    "    # Train logistic regression on this feature pair\n",
    "    lr_pair = LogisticRegression(random_state=42, class_weight='balanced', max_iter=1000)\n",
    "    lr_pair.fit(X_pair, y_encoded)\n",
    "    \n",
    "    # Create mesh grid\n",
    "    feature_1, feature_2 = np.meshgrid(\n",
    "        np.linspace(X_pair[:, 0].min() - 1, X_pair[:, 0].max() + 1, 100),\n",
    "        np.linspace(X_pair[:, 1].min() - 1, X_pair[:, 1].max() + 1, 100)\n",
    "    )\n",
    "    grid = np.vstack([feature_1.ravel(), feature_2.ravel()]).T\n",
    "    y_grid = lr_pair.predict(grid).reshape(feature_1.shape)\n",
    "    \n",
    "    # Plot decision boundary\n",
    "    display = DecisionBoundaryDisplay(xx0=feature_1, xx1=feature_2, response=y_grid)\n",
    "    display.plot(ax=axes[idx], alpha=0.4, cmap='RdYlGn')\n",
    "    \n",
    "    # Scatter actual points\n",
    "    scatter = axes[idx].scatter(X_pair[:, 0], X_pair[:, 1], c=y_encoded, \n",
    "                                 cmap='RdYlGn', edgecolor='black', s=50, alpha=0.7)\n",
    "    \n",
    "    axes[idx].set_xlabel(feature_columns[i])\n",
    "    axes[idx].set_ylabel(feature_columns[j])\n",
    "    axes[idx].set_title(f'{feature_columns[i]} vs {feature_columns[j]}')\n",
    "\n",
    "# Remove extra subplots\n",
    "for idx in range(n_plots, len(axes)):\n",
    "    fig.delaxes(axes[idx])\n",
    "\n",
    "fig.suptitle('Logistic Regression Decision Boundaries', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58965c9",
   "metadata": {},
   "source": [
    "## Report scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b35da62",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot precision/recall for 'spam' label at different thresholds\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import PchipInterpolator\n",
    "\n",
    "# Get class labels\n",
    "classes = classifier.classes_\n",
    "spam_idx = list(classes).index('spam')\n",
    "\n",
    "# Test different thresholds (more granular)\n",
    "thresholds = np.arange(0.05, 1.0, 0.02)\n",
    "precisions = []\n",
    "recalls = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred_thresh = np.where(y_proba[:, spam_idx] >= threshold, 'spam', 'good')\n",
    "    \n",
    "    precision, recall = report_at_threshold(threshold)\n",
    "    \n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "\n",
    "precisions = np.array(precisions)\n",
    "recalls = np.array(recalls)\n",
    "\n",
    "# Use PCHIP interpolation (monotonic, no overshoot)\n",
    "thresholds_smooth = np.linspace(thresholds.min(), thresholds.max(), 300)\n",
    "\n",
    "precision_interp = PchipInterpolator(thresholds, precisions)\n",
    "recall_interp = PchipInterpolator(thresholds, recalls)\n",
    "\n",
    "precisions_smooth = precision_interp(thresholds_smooth)\n",
    "recalls_smooth = recall_interp(thresholds_smooth)\n",
    "\n",
    "# Clip values to valid range [0, 1]\n",
    "precisions_smooth = np.clip(precisions_smooth, 0, 1)\n",
    "recalls_smooth = np.clip(recalls_smooth, 0, 1)\n",
    "\n",
    "# Plot precision and recall vs threshold\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax1.plot(thresholds_smooth, precisions_smooth, 'b-', linewidth=2, label='Precision')\n",
    "ax1.plot(thresholds_smooth, recalls_smooth, 'r-', linewidth=2, label='Recall')\n",
    "\n",
    "# Add original points as markers\n",
    "ax1.scatter(thresholds, precisions, color='blue', s=30, alpha=0.5, zorder=5)\n",
    "ax1.scatter(thresholds, recalls, color='red', s=30, alpha=0.5, zorder=5)\n",
    "\n",
    "ax1.set_xlabel('Threshold', fontsize=12)\n",
    "ax1.set_ylabel('Score', fontsize=12)\n",
    "ax1.set_title('Precision vs Recall at Different Thresholds (Spam Class)', fontsize=14)\n",
    "ax1.legend(loc='center right')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_xlim(0.05, 0.95)\n",
    "ax1.set_ylim(0, 1.05)\n",
    "\n",
    "# Mark default threshold (0.5)\n",
    "ax1.axvline(x=0.5, color='gray', linestyle='--', alpha=0.7, label='Default (0.5)')\n",
    "\n",
    "# Find and mark the threshold where precision = recall (F1 optimal point)\n",
    "diff = np.abs(precisions_smooth - recalls_smooth)\n",
    "optimal_idx = np.argmin(diff)\n",
    "ax1.scatter([thresholds_smooth[optimal_idx]], [precisions_smooth[optimal_idx]], \n",
    "            color='green', s=100, zorder=5, label=f'P=R @ {thresholds_smooth[optimal_idx]:.2f}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d73266",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "\n",
    "# Export tree to DOT format\n",
    "dot_data = export_graphviz(\n",
    "    classifier,\n",
    "    feature_names=feature_columns,\n",
    "    class_names=['Not Spam', 'Spam'],\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    impurity=False,\n",
    "    proportion=True,\n",
    "    special_characters=True\n",
    ")\n",
    "\n",
    "# Replace default colors with custom colors (blue for Not Spam, orange for Spam)\n",
    "# Class 0 (Not Spam) -> blue, Class 1 (Spam) -> orange\n",
    "dot_data = dot_data.replace('fillcolor=\"#', 'fillcolor=\"#temp')\n",
    "\n",
    "# Create custom color mapping based on class\n",
    "lines = dot_data.split('\\n')\n",
    "new_lines = []\n",
    "for line in lines:\n",
    "    if 'class = Not Spam' in line or \"value = [1.0, 0.0]\" in line:\n",
    "        line = line.replace('fillcolor=\"#temp', 'fillcolor=\"#3498db')\n",
    "    elif 'class = Spam' in line:\n",
    "        line = line.replace('fillcolor=\"#temp', 'fillcolor=\"#e67e22')\n",
    "    new_lines.append(line)\n",
    "\n",
    "dot_data = '\\n'.join(new_lines)\n",
    "\n",
    "# Display the tree\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c995010b",
   "metadata": {},
   "source": [
    "## Save the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff305c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the classifier and threshold for inference\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "# Create classifier directory if it doesn't exist\n",
    "Path('classifier').mkdir(exist_ok=True)\n",
    "\n",
    "# Save the classifier\n",
    "joblib.dump(classifier, 'classifier/spam_classifier.joblib')\n",
    "\n",
    "# Save the scaler (needed to normalize new data)\n",
    "joblib.dump(scaler, 'classifier/feature_scaler.joblib')\n",
    "\n",
    "# Save configuration\n",
    "config = {\n",
    "    'threshold': THRESHOLD,\n",
    "    'feature_columns': feature_columns,\n",
    "    'spam_class_index': list(classifier.classes_).index('spam'),\n",
    "    'classes': list(classifier.classes_)\n",
    "}\n",
    "\n",
    "joblib.dump(config, 'classifier/classifier_config.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HW3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
